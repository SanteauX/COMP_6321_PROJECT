{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4781bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import scipy\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67ec637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data file path(s)\n",
    "cwd = os.getcwd()\n",
    "parent_directory = os.path.dirname(cwd)\n",
    "data_directory = parent_directory + '\\\\data'\n",
    "data_paths = [\n",
    "    data_directory + '\\\\mr_bike_demand.csv',\n",
    "    data_directory + '\\\\mr_dock_demand.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8348ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_bike_demand = pd.read_csv(data_paths[0], index_col='start_date', parse_dates=['start_date']).asfreq('D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21331231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trip_count\n",
       "2014-01-01           0\n",
       "2014-01-02           0\n",
       "2014-01-03           0\n",
       "2014-01-04           0\n",
       "2014-01-05           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split station data into training and test set\n",
    "data_train = station_bike_demand['2014':'2018']\n",
    "data_test  = station_bike_demand['2019':'2019']\n",
    "\n",
    "# Add zeros for 2014 before April to have consistent period windows\n",
    "df = pd.DataFrame(index=pd.date_range(start='2014-01-01', end='2014-04-01', freq='D'), columns=['trip_count'])\n",
    "df['trip_count'] = 0\n",
    "data_train = pd.concat([df, data_train])\n",
    "\n",
    "# Exclude November data from the test set\n",
    "data_test  = data_test[:'2019-10-31']\n",
    "display(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb12ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1813, 3)\n",
      "(1813,)\n"
     ]
    }
   ],
   "source": [
    "#Generate Training Data\n",
    "\n",
    "#Split dates into day/month/year columns\n",
    "years = np.array(data_train.index.year)\n",
    "months = np.array(data_train.index.month)\n",
    "days = np.array(data_train.index.day)\n",
    "\n",
    "#Form feature vectors\n",
    "X_train_raw = np.column_stack((years,months,days))\n",
    "#Make target vector\n",
    "y_train_raw = np.array(data_train['trip_count'])\n",
    "\n",
    "#Verify Training X and y\n",
    "print(X_train_raw.shape)\n",
    "print(y_train_raw.shape)\n",
    "\n",
    "#print(X_train[X_train.shape[0]-5 : X_train.shape[0]])             \n",
    "#print(y_train[y_train.shape[0]-5 : X_train.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc488e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304, 3)\n",
      "(304,)\n"
     ]
    }
   ],
   "source": [
    "#Generate Test Data\n",
    "test_years = np.array(data_test.index.year)\n",
    "test_months = np.array(data_test.index.month)\n",
    "test_days = np.array(data_test.index.day)\n",
    "#Form feature vectors\n",
    "X_2019_test = np.column_stack((test_years,test_months,test_days))\n",
    "#Make target vector\n",
    "y_2019_test = np.array(data_test['trip_count'])\n",
    "\n",
    "\n",
    "print(X_2019_test.shape)\n",
    "print(y_2019_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8bd99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees used:  [ 38 236 397  73 256 394 204 134 336 449 145 130 461  72 238 391 282 179\n",
      " 277 255 358 403 469 396 253]\n",
      "Maximum tree Depths:  [ 3  5  8  8 10  2  8  1  7 10 10  8  7 10  2  1  2  9  9  4 10  9  8  4\n",
      "  7]\n"
     ]
    }
   ],
   "source": [
    "#Define Hyperparameters to search over\n",
    "np.random.seed(1)\n",
    "n_trials = 25\n",
    "num_trees = np.random.randint(1,500,size = n_trials)\n",
    "depths = np.random.randint(1,11,size = n_trials)\n",
    "print(\"Number of Trees used: \", num_trees)\n",
    "print(\"Maximum tree Depths: \", depths)\n",
    "\n",
    "#Define variables to hold results\n",
    "MSQ_by_trial = np.zeros(n_trials)\n",
    "percent_error_by_trial = np.zeros(n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e2954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model 1 of 25 num_trees: 38  and max_depth:  3\n",
      "Testing model 2 of 25 num_trees: 236  and max_depth:  5\n",
      "Testing model 3 of 25 num_trees: 397  and max_depth:  8\n"
     ]
    }
   ],
   "source": [
    "#Use time series variant of K-fold cross validation to generate estimates of Test time performance\n",
    "#Collect Data to later be used to define the final model.\n",
    "\n",
    "splitter=sklearn.model_selection.TimeSeriesSplit(n_splits = 4)\n",
    "j=0\n",
    "for n_trees,depth in zip(num_trees,depths):\n",
    "    i=0\n",
    "    #print(\"Testing model with hyperparams of num_trees:\",n_trees, \" and max_depth: \", depth)\n",
    "    print(\"Testing model {} of {}\".format(j+1,n_trials), \"num_trees:\", n_trees, \" and max_depth: \", depth)\n",
    "    percentage_errors = np.zeros(4)\n",
    "    MSQs = np.zeros(4)\n",
    "    for train_index, test_index in splitter.split(X_train_raw):\n",
    "        #print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "        X_train, X_test = X_train_raw[train_index], X_train_raw[test_index]\n",
    "        y_train, y_test = y_train_raw[train_index], y_train_raw[test_index]\n",
    "        i+=1\n",
    "        #Define and Fit our Model.\n",
    "        model = sklearn.ensemble.RandomForestRegressor(n_estimators= n_trees,\n",
    "                                                   max_depth = depth, random_state=0)\n",
    "        model = model.fit(X_train,y_train)\n",
    "        \n",
    "        #Make predictions and generate useful metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "        msq = sklearn.metrics.mean_squared_error(y_test,y_pred)\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_test,y_pred)\n",
    "\n",
    "        #Save metrics in an array for later analysis\n",
    "        percentage_errors[i-1] = mae/np.mean(y_test)*100\n",
    "        MSQs[i-1] = msq\n",
    "        \n",
    "        #print(\"For test fold \", i)\n",
    "        #print(\"Mean Squared Error: \", msq)\n",
    "        #print(\"Mean Absolute Error: \", mae)\n",
    "        #print(\"Mean of y_test: \", np.mean(y_test))\n",
    "        #print(\"Mean absolute % error: \", (mae/np.mean(y_test)*100),\"%\")\n",
    "   \n",
    "    #print(\"Average % error across test folds: \", np.mean(percentage_errors))\n",
    "    #print(\"Average MSQ across test folds: \", np.mean(MSQs))\n",
    "    MSQ_by_trial[j] = np.mean(MSQs)\n",
    "    percent_error_by_trial[j] = np.mean(percentage_errors)\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for plotting a summary of hyperparameter effects on MSQ\n",
    "plt.figure(figsize =(12,8));\n",
    "plt.scatter(num_trees, depths, marker = 'x', c = MSQ_by_trial)\n",
    "plt.colorbar()\n",
    "plt.title(\"Average MSQ over training of a Random Forest\")\n",
    "plt.xlabel(\"Number of Estimators\")\n",
    "plt.ylabel(\"Maximum Depth of Estimators\");\n",
    "#print(\"Min MSQ: \", np.min(MSQ_by_trial))\n",
    "#print(np.argmin(MSQ_by_trial))\n",
    "print(\"Best Classifier Attributes: \")\n",
    "print(\"Number of Estimators: \", num_trees[np.argmin(MSQ_by_trial)], \"Max Depth: \", depths[np.argmin(MSQ_by_trial)])\n",
    "print(\" Avg. % error of best classifier: \", percent_error_by_trial[np.argmin(MSQ_by_trial)] )\n",
    "print(\"MSQ of best classifer: \", MSQ_by_trial[np.argmin(MSQ_by_trial)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bfb03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Final Model Training and Performance\n",
    "#Define model using best parameters found in random sweep\n",
    "#Could perform more detailed sweep around target but the MSQ seems quite stable across depth >=3\n",
    "\n",
    "final_model = sklearn.ensemble.RandomForestRegressor(\n",
    "    n_estimators= num_trees[np.argmin(MSQ_by_trial)],\n",
    "    max_depth = depths[np.argmin(MSQ_by_trial)], random_state=0)\n",
    "\n",
    "#Train model on all data from 2014:2018\n",
    "model = model.fit(X_train_raw,y_train_raw)\n",
    "        \n",
    "#Make predictions and generate useful metrics\n",
    "y_final_pred = model.predict(X_2019_test)\n",
    "msq = sklearn.metrics.mean_squared_error(y_2019_test,y_final_pred)\n",
    "mae = sklearn.metrics.mean_absolute_error(y_2019_test,y_final_pred)\n",
    "\n",
    "print(\"Final num estimators used: \", num_trees[np.argmin(MSQ_by_trial)])\n",
    "print(\"Final max depth used: \", depths[np.argmin(MSQ_by_trial)])\n",
    "print(\"Mean Squared Error: \", msq)\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"Mean of y_test: \", np.mean(y_2019_test))\n",
    "print(\"Mean of y_pred: \", np.mean(y_final_pred))\n",
    "print(\"Mean absolute % error: \", (mae/np.mean(y_test)*100),\"%\")\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(data_test.index, y_final_pred, label = \"Predictions\")\n",
    "plt.plot(data_test.index, y_2019_test, label = \"True Values\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Bixie Usage\")\n",
    "plt.title(\"Final Model Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51594876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define helper function to split data by year.\n",
    "\n",
    "def get_data_by_year(year, X_data = X_train_raw, y_data = y_train_raw):\n",
    "    X = X_data[X_data[:,0] == year]\n",
    "    y = y_data[0:X.shape[0]]\n",
    "    return X,y\n",
    "\n",
    "#X,y = get_data_by_year(2016)\n",
    "#print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c0d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
